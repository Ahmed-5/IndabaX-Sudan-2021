{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 3: Deep Feed-forward Networks\n",
    "**IndabaX sudan 2019**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this practical, we implement and train a feed-forward neural network (also known as an \"MLP\" for \"multi-layer perceptron\") on a dataset called **\"Fashion MNIST\"**, consisting of small greyscale images of items of fashion. We consider the practical issues around generalisation to out-of-sample data and introduce some important techniques for addressing this.\n",
    "\n",
    "Before diving into the Neural network part we first have an introduction to Tensorflow, a very popular deep learning framework that is used in all aspects of defining, training and testing models. \n",
    "## Learning objectives\n",
    "* Understand the basics of Tensorflow\n",
    "* Use **Tensorflow Eager** and **Keras Layers** to build a neural network archetecture\n",
    "* Understand how a model is trained and evaluated\n",
    "* Differentiate between **in-sample** and **out-of-sample** model performance\n",
    "* Understand the concept of **train/validation/test split** and why it's useful\n",
    "* Research at least 1 techniques that can be used to improve model **generalisation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "As described in Wikipedia TensorFlow is a computational framework for building machine learning models. It is the second generation system from Google Brain headed by Jeff Dean. Launched in early 2017, it has disrupted the ML world by bringing in numerous capabilities from scalability to building production ready models.\n",
    "\n",
    "In other words, Tensorflow is a python library that provides matrix and list functionality and can work on multiple level of abstraction across multiple languages. Tensorflow is available on C++, python and recently on JavaScript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-d5e9fe680656>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install tensorflow-gpu==2.0.0-beta0 > /dev/null 2>&1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "#@title Imports (RUN ME!) { display-mode: \"form\" }\n",
    "\n",
    "!pip install tensorflow-gpu==2.0.0-beta0 > /dev/null 2>&1\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"TensorFlow executing eagerly: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For statrers, we can define a constant which is a tensor whose value cannot be changed at all. It can take many shapes and dimentions as the examples below show.\n",
    "\n",
    "We can also declare variable tensors which values change. Their declaration is abit different but the code below shows the difference between the two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8fd2894266ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#for declaring constants we use the ft.constant function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mx1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m            \u001b[1;31m#shape ()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m#shape (3,)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#we can use tf.stack to create higher dimentinal matricies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m        \u001b[1;31m#shape (2, 3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "#for declaring constants we use the ft.constant function\n",
    "x1 = tf.constant(3)            #shape ()\n",
    "x2 = tf.constant([3, 5, 7])    #shape (3,)\n",
    "#we can use tf.stack to create higher dimentinal matricies\n",
    "x3 = tf.stack([x2, x2])        #shape (2, 3)\n",
    "\n",
    "#for declaring a variable we use the function tf.get_variable and we manuplate them using the tf.variable class\n",
    "my_var = tf.get_variable(\"my_var\", [1, 2, 3])\n",
    "\n",
    "print (x1, x2, x3, my_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might have noticed, running the above code results in printing tensor abstract but not the values themselves. This is because a Tensorflow code is just an abstract representation of what will be run in the Tensorflow session. A session encapsulates state of Tensorflow runtime and runs Tensorflow operations. Tesnorflow represents the written code in an unserlying graph. Take the following code, it is represented by the grave underneath it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sesions = tf.Session()\n",
    "x = tf.constant([1, 2, 3], name = \"x\")\n",
    "y = tf.constant([4, 5, 6], name = \"y\")\n",
    "z1 = tf.add(x, y, name = \"z1\")\n",
    "z2 = x * y\n",
    "z3 = z2- z1"
   ]
  },
  {
   "attachments": {
    "tf%20graph.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tf%20graph.png](attachment:tf%20graph.png)\n",
    "\n",
    "when we run the session thats when the value are inputed and we can get the values of the Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sessions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8727886246cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sessions' is not defined"
     ]
    }
   ],
   "source": [
    "print(sessions.run(z3))\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic TensorFlow operations\n",
    "#### Addition and Subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = tf.constant([1, 2, 3])\n",
    "a2 = tf.constant([3, 4, 5])\n",
    "a3 = a1 + a2 # (tf.add(a1, a2) also works. TensorFlow supports primitive operators)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    print(session.run(a3))\n",
    "\n",
    "# Result [4, 6, 8]\n",
    "\n",
    "a4 = a1 - a2\n",
    "with tf.Session() as session:\n",
    "    ptint(session.run(a4))\n",
    "\n",
    "# Result [-2, -2, -2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiplication and Division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = tf.constant([1, 2, 3])\n",
    "a2 = tf.constant([3, 4, 5])\n",
    "a3 = a1 * a2 # (tf.mul(a1, a2) also works. TensorFlow supports primitive operators)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    print(session.run(a3))\n",
    "\n",
    "# Result [3, 8, 15]\n",
    "\n",
    "a4 = a1/a2\n",
    "with tf.Session() as session:\n",
    "    print(a4.eval())  # eval() can be used instead of session.run() to compute the results of a particular variable.\n",
    "    \n",
    "\n",
    "# Result [0.34, 0.5, 0.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = tf.constant([3, 5, 7],\n",
    "                 [4, 6, 8])  # Shape is (2, 3)\n",
    "a2 = tf.reshape(a1, [3, 2])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(a2)\n",
    "    print(a2)\n",
    "    \n",
    "# Result[[3, 5], [7, 4], [6, 8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we got the basics of tensorflow we can delve into the meat of the practical and start on the Feed-forward Network\n",
    "### The Data\n",
    "In this practical, we use the Fashion MNIST dataset consisting of 70,000 greyscale images and their labels. The dataset is divided\n",
    " into 60,000 training images and 10,000 test images. The idea is to train a **classifier** to identify the class value (what type of fashion item it is) given the image. We train and *tune* a model on the 60,000 training images and then evaluate how well it classifies the 10,000 test images that the model did not see during training. This task is an example of a **supervised learning** problem, where we are given both input and labels (targets) to learn from. This is in contrast to **unsupervised learning** where we only have inputs from which to learn patterns or **reinforcement learning** where an agent learns how to maximise a reward signal through interaction with its environment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b471c90504c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Tensorflow has convenient modules for loading a number of standard datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfashion_mnist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfashion_mnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_and_validation_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_and_validation_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtext_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'T-shirt/top'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Trouser'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Pullover'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Dress'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Coat'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sandal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Shirt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sneaker'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Bag'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Ankle boot'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Tensorflow has convenient modules for loading a number of standard datasets\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_and_validation_images, train_and_validation_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "text_labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional extra reading: Train/Validation/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we build machine learning models, the goal is to build a model that will perform well on *future* data that we have not seen yet. We say that we want our models to be able to **generalise** well from whatever training data we can collect and do have available, to whatever data we will be applying them to in future. To do this, we split whatever data we have available into a **training set, a validation set and a test set**. The idea is that we train our model and use the performance on the validation set to make any adjustments to the model and its hyperparameters, but then we report the final accuracy on the test set. The test set (which we never train on), therefore acts as a proxy for our future data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a validation set\n",
    "Next, we remove 10,000 images and labels from the training set to use as a validation set. We will come back to the validation set later! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a validation set from the last 10000 images and labels from\n",
    "# train_and_validation_images and train_and_validation_labels\n",
    "validation_images = train_and_validation_images[-10000:, :, :]\n",
    "validation_labels = train_and_validation_labels[-10000:]\n",
    "\n",
    "# Construct a training set from the first 50000 images and labels.\n",
    "train_images = train_and_validation_images[:50000, :, :]\n",
    "train_labels = train_and_validation_labels[:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does the data look like?\n",
    "Each image in the dataset consists of a 28 x 28 matrix of greyscale pixels. The values are between 0 and 255 where 0 represents black, 255 represents white and there are many shades of grey in-between. Each image is assigned a corresponding numerical label, so the image in ```train_images[i]``` has its corresponding label stored in ```train_labels[i]```. We also have a lookup array called ```text_labels``` to associate a text description with each of the numerical labels. For example, the label 1 is associated with the text description \"Trouser\".\n",
    "\n",
    "The 2 cells below demonstrate how to visualise the input data. Make sure you understand what's happening, particularly how the indices correspond to individual items in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the Matplotlib plotting library to visualise an image selected at random from the training set\n",
    "plt.figure()\n",
    "random_index = np.random.randint(0, len(train_images))\n",
    "plt.imshow(train_images[random_index], cmap='gray_r')\n",
    "plt.colorbar()\n",
    "numerical_label = train_labels[random_index]\n",
    "text_description = text_labels[numerical_label]\n",
    "plt.title('True Class: {} (\"{}\")'.format(numerical_label, text_description))\n",
    "\n",
    "plt.gca().grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another view, showing 25 randomly selected images at a time\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "\n",
    "    img_index = np.random.randint(0, 50000)\n",
    "    plt.imshow(train_images[img_index], cmap=\"gray_r\")\n",
    "    plt.xlabel(text_labels[train_labels[img_index]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Task\n",
    "Run the above cells multiple times to get a good sense of the dataset. Look at the general structure of the images and their corresponding labels. Can you spot some classes that might be difficult for a classifier to distinguish? If so, why do you think they would be difficult to distinguish? Chat to your neighbour about this. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data with TensorFlow\n",
    "At the moment, our training data consists of two large tensors. The images are stored in a tensor of shape $[50000, 28, 28]$, consisting of all the $28 \\times 28$ images matrices stacked together. The labels are stored in a 1D vector of shape $[50000]$. We wish to train a model using **mini-batch stochastic gradient descent**. In order to do so, we need to shuffle the data and split it into smaller (mini-)batches. We also convert the data from numpy arrays to TensorFlow Tensors.\n",
    "\n",
    "#### Questions\n",
    "* Can you explain what the difference is between normal stochastic gradient descent and \"batched\" stochastic gradient descent? What is the purpose of chunking data into batches during training? Are there any trade-offs? What are they? **HINT**: Speak to your neighbours and tutors about this. You can also read [this blog post](https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/) for more details.\n",
    "* Why is it important to randomise the data before chunking it into batches? \n",
    "\n",
    "In order to do this batching (and shuffling) we will use the Tensorflow [Dataset API](https://www.tensorflow.org/api_docs/python/tf/data/Dataset), which is a set of simple reusable components that allow you to build efficient data pipelines. Data is said to \"stream\" through the pipeline, meaning that when something at the output of the pipeline wants data, the pipeline will provide that data as soon as it has enough, rather than waiting to process all the data. This allows you to easily build pipelines that work on large datasets without having to load it all into memory in one go!\n",
    "\n",
    "We build this pipeline step-by-step:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining the ```batch_size``` hyperparameter of our model. This hyperparameter controls the sizes of the mini-batches (chunks) of data that we use to train the model. The value you use will affect the memory usage, speed of convergence and potentially also the performance of the model. It also interacts with the *learning rate* used in gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first component we add will group the image and label tensors together into a tuple and then split them into individual entries - ie. 50000 tuples containing a (28, 28) dimensional image and 1D label associated with that image. The following line adds this splitting component to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_images, train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we do is apply a map operation. This lets us run an arbitrary function on each element. The function we provide returns the image values divided by 255 and converted ('cast') to a float and the label converted to a 32-bit integer.\n",
    "\n",
    "**NOTE**: \"Lambda\" functions are just one-line, anonymous functions. In this case, it defines a function that takes arguments x and y (before the colon), and outputs their manipulated values (after the colon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide image values and cast to float so that they end up as a floating point number between 0 and 1\n",
    "train_ds = train_ds.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, tf.cast(y, tf.int32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we add a **shuffle** component. This returns a random element from the pipeline. Can you spot a potential problem here? \n",
    "\n",
    "**QUESTION**:  What might happen if the shuffle component didn't have a *buffer*?  **HINT**: Refer back to the discussion about the data pipeline and \"data streaming through it\" above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the examples.\n",
    "train_ds = train_ds.shuffle(buffer_size=batch_size * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final component in our pipeline is the batch component. This just requests `batch_size` elements from the previous pipeline component, groups them together into a single tensor and returns that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now \"chunk\" the examples into batches\n",
    "train_ds = train_ds.batch(batch_size)\n",
    "\n",
    "# The output of this pipeline will be tuples of tensors containing images and labels.\n",
    "# The images will be of shape (batch_size, 28, 28) and the labels of shape (batch_size, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we apply the same pre-processing (converting to Tensors and normalising the values to lie between 0 and 1) to the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't worry about this for now, we will use the validation set later\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((validation_images, validation_labels))\n",
    "val_ds = val_ds.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, tf.cast(y, tf.int32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "In this section we'll build a classifier. A **classifier** is a function that takes an object's characteristics (or \"features\") as inputs and outputs a prediction of the class (or group) that the object belongs to. It may make a single prediction for each input or it may output some score (for example a probability) for each of the possible classes. Specifically, we will build a classifier that takes in (a batch of) 28 x 28 Fashion MNIST images as we've seen above, and outputs predictions about which class the image belongs to. \n",
    "\n",
    "For each (batch of) input images, we will use a **feed-forward neural network** to compute un-normalised scores (also known as **logits**) for each of the 10 possible classes that the image could belong to. We can then **classify** the image as belonging to the class which receives the highest score, or we can quantify the model's \"confidence\" about the classifications by converting the scores into a probability distribution. \n",
    "\n",
    "A feed-forward neural network consisting of $N$ layers, applied to an input vector $\\mathbf{x}$ can be defined as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{f_0} = \\mathbf{x} \\\\\n",
    "\\mathbf{f_i} = \\sigma_i(\\mathbf{W_if_{i-1}} + \\mathbf{b_i}) \\ \\ \\ i \\in [1, N]\n",
    "\\end{equation}\n",
    "\n",
    "Each layer has a particular number, $m_i$, of neurons. The parameters of a layer consist of a matrix $\\mathbf{W_i} \\in \\mathbb{R}^{m_i \\times m_{i-1}}$ and bias vector $\\mathbf{b_i} \\in \\mathbb{R}^{m_i}$. Each layer also has a non-linear activation function $\\sigma_i$. \n",
    "\n",
    "**QUESTION**: Why do you think the activation functions need to be *non-linear*? What would happen if they were *linear*? **HINT**: If you're stuck, consider the very simplest case of an identity activation (which essentially does nothing) and ignore the biases. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional extra reading: Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Activation functions are a core ingredient in deep neural networks. In fact they are what allows us to make use of multiple layers in a neural network. There are a number of different activation functions, each of which are more or less useful under different circumstances. The four activation functions that you are most likely to encounter are, arguably, [ReLU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/ReLU), [Tanh](https://www.tensorflow.org/api_docs/python/tf/keras/activations/tanh), [Sigmoid](https://www.tensorflow.org/api_docs/python/tf/keras/activations/sigmoid), and [Softmax](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Softmax). \n",
    "\n",
    "ReLU, has in recent years, become the default choice for use in MLPs and Convolutional Neural Networks (CNNs). ReLU has two advantages over Tanh and Sigmoid: it is computationally much more efficient, and, it allows us to use deeper networks because it does not suffer from [vanishing gradients](https://en.wikipedia.org/wiki/Vanishing_gradient_problem). As a result of their success, a number of ReLU variants, such as [LeakyRelu](https://www.tensorflow.org/api_docs/python/tf/keras/layers/LeakyReLU) and [PReLU](https://www.tensorflow.org/api_docs/python/tf/keras/layers/PReLU), have been developed.\n",
    "\n",
    "Sigmoid and Softmax activations are often found after the last layer in binary and multi-class classification networks, respectively, as they transform the outputs of the network in such a way that we can interpret them as class probabilities.\n",
    "\n",
    "Both Tanh and Sigmoid are found in LSTM and GRU recurrent neural networks, which we will find out more about in the coming days. They are also useful in MLPs and CNNs where we want the output to be bounded between -1 and 1 (Tanh) or 0 and 1 (Sigmoid).\n",
    "\n",
    "Read more about activation functions [here](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
